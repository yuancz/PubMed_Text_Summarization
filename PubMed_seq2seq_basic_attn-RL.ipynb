{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import re\n",
    "from time import sleep\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "import pickle\n",
    "import layers\n",
    "import functions\n",
    "import decoder\n",
    "import encoder\n",
    "from dataset import PubMed_Dataset\n",
    "import data_batcher\n",
    "import models\n",
    "import summarizer\n",
    "import data_utils\n",
    "from sys import stdout\n",
    "from vocab import Vocab_Lookup\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta_dir = os.path.join(os.getcwd(), 'PubMed')\n",
    "log_dir = os.path.join(meta_dir, 'logs')\n",
    "weights_dir = os.path.join(meta_dir, 'weights')\n",
    "params_dir = os.path.join(meta_dir, 'params')\n",
    "data_dir = os.path.join(meta_dir, 'data_cache')\n",
    "\n",
    "coherence_ckpt_file = os.path.join(meta_dir, 'weights/RNN_Classifier_checkpoints_20171117_114517/RNN_Classifier_weights_epoch_0_itr_38000')\n",
    "coherence_params = pickle.load(open(os.path.join(meta_dir, 'params/RNN_Classifier_params_20171117_114517.pickle'), 'rb'))\n",
    "summarize_ckpt_file = os.path.join(meta_dir, 'weights/Seq2Seq_Basic_Attn_checkpoints_20171116_151612/Seq2Seq_Basic_Attn_weights_epoch_1_itr_130000')\n",
    "summarize_params = pickle.load(open(os.path.join(params_dir, 'Seq2Seq_Basic_Attn_params_20171116_151612.pickle'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_lookup = pickle.load(open(os.path.join(meta_dir, \"vocab_lookup_30000.pickle\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_files = []\n",
    "val_files = []\n",
    "test_files = []\n",
    "for filename in os.listdir(data_dir):\n",
    "    if 'train' in filename:\n",
    "        train_files.append(os.path.join(data_dir, filename))\n",
    "    elif 'val' in filename:\n",
    "        val_files.append(os.path.join(data_dir, filename))\n",
    "    elif 'test' in filename:\n",
    "        test_files.append(os.path.join(data_dir, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_partition_loader(partition_files):\n",
    "    i = 0\n",
    "    while True:\n",
    "        partition_file = partition_files[i]\n",
    "        i += 1\n",
    "        yield pickle.load(open(partition_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_partition_loader = data_partition_loader(train_files)\n",
    "val_partition_loader = data_partition_loader(val_files)\n",
    "test_partition_loader = data_partition_loader(test_files)\n",
    "\n",
    "train_data = next(train_partition_loader)\n",
    "val_data = next(val_partition_loader)\n",
    "test_data = next(test_partition_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_batcher = data_batcher.Data_Batcher(train_data, batch_size)\n",
    "val_batcher = data_batcher.Data_Batcher(val_data, batch_size)\n",
    "test_batcher = data_batcher.Data_Batcher(test_data, batch_size)\n",
    "deploy_batcher = data_batcher.Data_Batcher(val_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_pad_len = summarize_params['max_enc_len']\n",
    "s_pad_len = summarize_params['max_dec_len']\n",
    "embd_dim = summarize_params['embedding_dim']\n",
    "hidden_size = summarize_params['hidden_size']\n",
    "n_layers = summarize_params['n_layers']\n",
    "vocab_size = vocab_lookup.num_words\n",
    "dropout_keep_prob = 0.8\n",
    "bidirectional = summarize_params['bidirectional']\n",
    "shared_embeddings = summarize_params['shared_embeddings']\n",
    "weight_tying = summarize_params['weight_tying']\n",
    "teacher_forcing_ratios = [1.0] \n",
    "teacher_forcing_steps = [1]\n",
    "\n",
    "display_interval = 100\n",
    "val_interval = 1000\n",
    "deploy_interval = 1000\n",
    "n_iters = 200000 \n",
    "\n",
    "lr = 0.0001\n",
    "DEVICE = 1\n",
    "USE_CUDA = True\n",
    "DEBUG_MODE = False\n",
    "\n",
    "pretrained_embeddings = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import ToktokTokenizer\n",
    "toktok = ToktokTokenizer()\n",
    "rouge = Rouge()\n",
    "\n",
    "def convert_text_to_ids(text, word2id_dict, pad_len):\n",
    "    tokenized = data_utils.tokenize_sentences(text, tokenizer=toktok)\n",
    "    ids = []\n",
    "    for word in tokenized:\n",
    "        try:\n",
    "            idx = word2id_dict[word]\n",
    "        except:\n",
    "            idx = word2id_dict['UNK']\n",
    "        ids.append(idx)\n",
    "    if len(ids) < pad_len:\n",
    "        ids += [match_lstm_word2id['PAD'] for i in range(pad_len - len(ids))]\n",
    "    elif len(ids) > pad_len:\n",
    "        ids = ids[:pad_len]\n",
    "    return ids\n",
    "\n",
    "def truncate_at_eos(string):\n",
    "    string = string.split(' ')\n",
    "    try:\n",
    "        new_string = ' '.join(string[:string.index('EOS')+1])\n",
    "    except:\n",
    "        new_string = ' '.join(string)\n",
    "    return new_string\n",
    "\n",
    "def ids_to_text(ids, vocab_lookup):\n",
    "    texts = [' '.join([vocab_lookup.convert_id2word(idx) for idx in tokens]) for tokens in ids]\n",
    "    truncated_texts = [truncate_at_eos(string) for string in texts]\n",
    "    return truncated_texts\n",
    "\n",
    "def text_to_ids(texts, vocab_lookup, pad_len):\n",
    "    ids = [[vocab_lookup.convert_word2id(idx) for idx in text.split(' ')] for text in texts]\n",
    "    ids = [seq + [vocab_lookup.convert_word2id('EOS')] for seq in ids]\n",
    "    new_ids = []\n",
    "    for seq in ids:\n",
    "        if len(seq) < pad_len:\n",
    "            seq += [vocab_lookup.convert_word2id('PAD') for i in range(pad_len - len(seq))]\n",
    "        elif len(seq) > pad_len:\n",
    "            seq = seq[:pad_len-1] + [vocab_lookup.convert_word2id('EOS')]\n",
    "        new_ids.append(seq)\n",
    "    return new_ids\n",
    "\n",
    "def get_text_length(texts):\n",
    "    return [len(text.split(' ')) for text in texts]\n",
    "\n",
    "def calc_rouge_reward(summaries, target_texts):\n",
    "    rouge_scores = rouge.get_scores(summaries, target_texts)\n",
    "    rouge_reward = np.array([scores['rouge-l']['f'] for scores in rouge_scores])\n",
    "    return rouge_reward\n",
    "\n",
    "def calc_unk_reward(summaries):\n",
    "    summary_lengths = [len(summary.split(' ')) for summary in summaries]\n",
    "    unk_count = [sum([1 if word == 'UNK' else 0 for word in summary.split(' ')]) for summary in summaries]\n",
    "    unk_reward = 1 - np.array(unk_count)/np.array(summary_lengths)\n",
    "    return unk_reward\n",
    "\n",
    "def calc_length_reward(summaries, max_len):\n",
    "    summary_lengths = [len(summary.split(' ')) for summary in summaries]\n",
    "    length_reward = np.array(summary_lengths)/max_len\n",
    "    return length_reward\n",
    "\n",
    "def calc_lm_reward(summaries, pad_len):\n",
    "    summary_ids = text_to_ids(summaries, vocab_lookup, pad_len)\n",
    "    summary_lens = [len(summary.split(' ')) for summary in summaries]\n",
    "    feed_dict = {language_net.enc_inputs : summary_ids,\n",
    "                 language_net.enc_lens : summary_lens,\n",
    "                 language_net.seed_length : len(summary_ids[0]),\n",
    "                 language_net.dropout_keep_prob : 1.0}\n",
    "    lm_reward = language_sess.run(normalized_probs, feed_dict=feed_dict)\n",
    "    return lm_reward\n",
    "\n",
    "def calc_coherence_reward(summaries, pad_len):\n",
    "    summary_ids = text_to_ids(summaries, vocab_lookup, pad_len)\n",
    "    summary_lens = [len(summary.split(' ')) for summary in summaries]\n",
    "    feed_dict = {coherence_net.inputs : summary_ids,\n",
    "                 coherence_net.input_lens : summary_lens,\n",
    "                 coherence_net.dropout_keep_prob : 1.0}\n",
    "    coherence_reward = coherence_sess.run(coherence_score, feed_dict=feed_dict)\n",
    "    return np.squeeze(coherence_reward)\n",
    "\n",
    "def calculate_reward(summary_ids, target_ids, unk_weight=0.1, length_weight=0.0, rouge_weight=0.7, lm_weight=0.0,\n",
    "                     coherence_weight=0.2):\n",
    "    summaries = ids_to_text(summary_ids, vocab_lookup)\n",
    "    targets = ids_to_text(target_ids, vocab_lookup)\n",
    "\n",
    "    rouge_reward = calc_rouge_reward(summaries, targets)\n",
    "    coherence_reward = calc_coherence_reward(summaries, s_pad_len)\n",
    "    unk_reward = calc_unk_reward(summaries)\n",
    "#     length_reward = calc_length_reward(summaries, s_pad_len)\n",
    "#     lm_reward = calc_lm_reward(summaries, s_pad_len)\n",
    "    total_reward = unk_weight*unk_reward + rouge_weight*rouge_reward + coherence_weight*coherence_reward\n",
    "    return total_reward.astype(np.float32)\n",
    "\n",
    "def get_seq_len_wrapper(ids):\n",
    "    texts = ids_to_text(ids, vocab_lookup)\n",
    "    return np.array([len(s.split(' ')) for s in texts], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Trainable Parameters: 4456385\n",
      "<tf.Variable 'embeddings_layer/embeddings:0' shape=(30000, 100) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0' shape=(356, 512) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_0/gru_cell/gates/bias:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0' shape=(356, 256) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_1/gru_cell/gates/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_1/gru_cell/gates/bias:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_1/gru_cell/candidate/kernel:0' shape=(512, 256) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_1/gru_cell/candidate/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_2/gru_cell/gates/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_2/gru_cell/gates/bias:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_2/gru_cell/candidate/kernel:0' shape=(512, 256) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_2/gru_cell/candidate/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_3/gru_cell/gates/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_3/gru_cell/gates/bias:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_3/gru_cell/candidate/kernel:0' shape=(512, 256) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_3/gru_cell/candidate/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'dense_output/output_W:0' shape=(256, 1) dtype=float32_ref>\n",
      "<tf.Variable 'dense_output/output_b:0' shape=(1,) dtype=float32_ref>\n",
      "# Trainable Parameters: 8427092\n",
      "<tf.Variable 'embeddings_layer/embeddings:0' shape=(30000, 100) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0' shape=(612, 1024) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_0/gru_cell/gates/bias:0' shape=(1024,) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0' shape=(612, 512) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_1/gru_cell/gates/kernel:0' shape=(1024, 1024) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_1/gru_cell/gates/bias:0' shape=(1024,) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_1/gru_cell/candidate/kernel:0' shape=(1024, 512) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_1/gru_cell/candidate/bias:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'attention/attn_W:0' shape=(512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'attention/attn_v:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/proj_W:0' shape=(1024, 100) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/dec_b:0' shape=(30000,) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/go_var:0' shape=(100,) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0' shape=(612, 1024) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/multi_rnn_cell/cell_0/gru_cell/gates/bias:0' shape=(1024,) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0' shape=(612, 512) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/multi_rnn_cell/cell_1/gru_cell/gates/kernel:0' shape=(1024, 1024) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/multi_rnn_cell/cell_1/gru_cell/gates/bias:0' shape=(1024,) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/multi_rnn_cell/cell_1/gru_cell/candidate/kernel:0' shape=(1024, 512) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/multi_rnn_cell/cell_1/gru_cell/candidate/bias:0' shape=(512,) dtype=float32_ref>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2-leia/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Trainable Parameters: 8427092\n",
      "<tf.Variable 'embeddings_layer/embeddings:0' shape=(30000, 100) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0' shape=(612, 1024) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_0/gru_cell/gates/bias:0' shape=(1024,) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0' shape=(612, 512) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_1/gru_cell/gates/kernel:0' shape=(1024, 1024) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_1/gru_cell/gates/bias:0' shape=(1024,) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_1/gru_cell/candidate/kernel:0' shape=(1024, 512) dtype=float32_ref>\n",
      "<tf.Variable 'encoder/multi_rnn_cell/cell_1/gru_cell/candidate/bias:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'attention/attn_W:0' shape=(512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'attention/attn_v:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/proj_W:0' shape=(1024, 100) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/dec_b:0' shape=(30000,) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/go_var:0' shape=(100,) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0' shape=(612, 1024) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/multi_rnn_cell/cell_0/gru_cell/gates/bias:0' shape=(1024,) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0' shape=(612, 512) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/multi_rnn_cell/cell_1/gru_cell/gates/kernel:0' shape=(1024, 1024) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/multi_rnn_cell/cell_1/gru_cell/gates/bias:0' shape=(1024,) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/multi_rnn_cell/cell_1/gru_cell/candidate/kernel:0' shape=(1024, 512) dtype=float32_ref>\n",
      "<tf.Variable 'decoder/multi_rnn_cell/cell_1/gru_cell/candidate/bias:0' shape=(512,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "device_name = '/gpu:{}'.format(DEVICE) if USE_CUDA else '/cpu:{}'.format(DEVICE)\n",
    "\n",
    "if USE_CUDA:\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"{}\".format(DEVICE)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "baseline_graph = tf.Graph()\n",
    "summarize_graph = tf.Graph()\n",
    "coherence_graph = tf.Graph()\n",
    "\n",
    "with coherence_graph.as_default(), tf.device(device_name):\n",
    "    coherence_net = models.RNN_Classifier(1, coherence_params['vocab_size'], s_pad_len, \n",
    "                                          embedding_dim=coherence_params['embedding_dim'], \n",
    "                                          hidden_size=coherence_params['hidden_size'], \n",
    "                                          n_layers=coherence_params['n_layers'], \n",
    "                                          bidirectional=coherence_params['bidirectional'], \n",
    "                                          pretrained_embeddings=None, trainable_embeddings=True)\n",
    "    coherence_vars = tf.trainable_variables()\n",
    "    coherence_score = tf.nn.sigmoid(coherence_net.logits)\n",
    "    coherence_score = tf.to_float(coherence_score >= 0.5)\n",
    "    coherence_init = tf.global_variables_initializer()\n",
    "    functions.count_params(tf.trainable_variables())\n",
    "    for var in tf.trainable_variables(): print(var)\n",
    "\n",
    "with baseline_graph.as_default(), tf.device(device_name):\n",
    "    baseline_net = models.Seq2Seq_Basic_Attn(vocab_size, d_pad_len, s_pad_len, embedding_dim=embd_dim, \n",
    "                                              hidden_size=hidden_size, n_layers=n_layers, bidirectional=bidirectional, \n",
    "                                              pretrained_embeddings=pretrained_embeddings, trainable_embeddings=True, \n",
    "                                              shared_embeddings=shared_embeddings, weight_tying=weight_tying)\n",
    "    baseline_vars = tf.trainable_variables()\n",
    "    baseline_softmax = tf.nn.softmax(baseline_net.logits)\n",
    "    baseline_predictions = tf.to_int32(tf.argmax(baseline_softmax, axis=2))\n",
    "    \n",
    "    baseline_init = tf.global_variables_initializer()\n",
    "    functions.count_params(tf.trainable_variables())\n",
    "    for var in tf.trainable_variables(): print(var)\n",
    "    \n",
    "with summarize_graph.as_default(), tf.device(device_name):\n",
    "    summarize_net = models.Seq2Seq_Basic_Attn(vocab_size, d_pad_len, s_pad_len, embedding_dim=embd_dim, \n",
    "                                              hidden_size=hidden_size, n_layers=n_layers, bidirectional=bidirectional, \n",
    "                                              pretrained_embeddings=pretrained_embeddings, trainable_embeddings=True, \n",
    "                                              shared_embeddings=shared_embeddings, weight_tying=weight_tying)\n",
    "    summarize_vars = tf.trainable_variables()\n",
    "    summarize_logits = summarize_net.logits\n",
    "    summarize_predictions = summarize_net.generated_words\n",
    "    summarize_softmax = tf.nn.softmax(summarize_logits)\n",
    "\n",
    "    indices = tf.reshape(summarize_predictions, [-1])\n",
    "    indices = indices + tf.range(tf.shape(summarize_softmax)[0]*tf.shape(summarize_softmax)[1])*tf.shape(summarize_softmax)[2]\n",
    "    action_probs = tf.reshape(tf.gather(tf.reshape(summarize_softmax, [-1]), indices), [-1, s_pad_len])\n",
    "    \n",
    "    log_probs = tf.squeeze(tf.log(action_probs))\n",
    "    generated_seq_lens = tf.py_func(get_seq_len_wrapper, [summarize_predictions], tf.int32)\n",
    "    generated_seq_lens = tf.reshape(generated_seq_lens, [-1])\n",
    "    mask = tf.sequence_mask(generated_seq_lens, maxlen=s_pad_len)\n",
    "    masked_log_probs = tf.to_float(mask)*log_probs\n",
    "    seq_probs = tf.reduce_sum(masked_log_probs, axis=1)\n",
    "    \n",
    "    targets = tf.placeholder(tf.int32, shape=[None, s_pad_len], name='targets')\n",
    "    reward = tf.py_func(calculate_reward, [summarize_predictions, targets], tf.float32)\n",
    "    baseline_reward = tf.placeholder(tf.float32, shape=[None], name='baseline_reward')\n",
    "    \n",
    "    reward_loss = seq_probs*(baseline_reward - reward)\n",
    "    loss = tf.reduce_mean(reward_loss)\n",
    "\n",
    "    gradients, _ = tf.clip_by_global_norm(tf.gradients(loss, summarize_vars), 1) \n",
    "    gradient_norm = tf.global_norm(gradients)\n",
    "    opt_func = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    optimizer = opt_func.apply_gradients(zip(gradients, summarize_vars)) \n",
    "    \n",
    "    summarize_init = tf.global_variables_initializer()\n",
    "    functions.count_params(tf.trainable_variables())\n",
    "    for var in tf.trainable_variables(): print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/ai2-leia/Documents/code/paul/deep_NLP/Summarization/PubMed/weights/Seq2Seq_Basic_Attn_checkpoints_20171116_151612/Seq2Seq_Basic_Attn_weights_epoch_1_itr_130000\n",
      "INFO:tensorflow:Restoring parameters from /home/ai2-leia/Documents/code/paul/deep_NLP/Summarization/PubMed/weights/Seq2Seq_Basic_Attn_checkpoints_20171116_151612/Seq2Seq_Basic_Attn_weights_epoch_1_itr_130000\n",
      "INFO:tensorflow:Restoring parameters from /home/ai2-leia/Documents/code/paul/deep_NLP/Summarization/PubMed/weights/RNN_Classifier_checkpoints_20171117_114517/RNN_Classifier_weights_epoch_0_itr_38000\n",
      "[0,     1] loss: -3.128, greedy reward: 0.532, sampled reward: 0.478, rouge-1: 0.426, rouge-2: 0.191, rouge-L: 0.373, grad_norm: 1.000\n",
      "[0,   100] loss: -2.227, greedy reward: 0.556, sampled reward: 0.508, rouge-1: 0.427, rouge-2: 0.176, rouge-L: 0.376, grad_norm: 0.756\n",
      "[0,   200] loss: -1.625, greedy reward: 0.571, sampled reward: 0.526, rouge-1: 0.441, rouge-2: 0.193, rouge-L: 0.384, grad_norm: 0.528\n",
      "[0,   300] loss: -1.480, greedy reward: 0.573, sampled reward: 0.520, rouge-1: 0.447, rouge-2: 0.184, rouge-L: 0.387, grad_norm: 0.641\n",
      "[0,   400] loss: -1.174, greedy reward: 0.567, sampled reward: 0.532, rouge-1: 0.431, rouge-2: 0.195, rouge-L: 0.378, grad_norm: 0.516\n",
      "[0,   500] loss: -0.731, greedy reward: 0.562, sampled reward: 0.534, rouge-1: 0.429, rouge-2: 0.181, rouge-L: 0.373, grad_norm: 0.470\n",
      "[0,   600] loss: -0.878, greedy reward: 0.576, sampled reward: 0.544, rouge-1: 0.462, rouge-2: 0.200, rouge-L: 0.401, grad_norm: 0.587\n",
      "[0,   700] loss: -0.414, greedy reward: 0.554, sampled reward: 0.539, rouge-1: 0.419, rouge-2: 0.164, rouge-L: 0.363, grad_norm: 0.531\n",
      "[0,   800] loss: -0.394, greedy reward: 0.569, sampled reward: 0.552, rouge-1: 0.456, rouge-2: 0.196, rouge-L: 0.392, grad_norm: 0.429\n",
      "[0,   900] loss: -0.367, greedy reward: 0.563, sampled reward: 0.545, rouge-1: 0.436, rouge-2: 0.176, rouge-L: 0.375, grad_norm: 0.479\n",
      "[0,  1000] loss: -0.351, greedy reward: 0.563, sampled reward: 0.551, rouge-1: 0.431, rouge-2: 0.167, rouge-L: 0.377, grad_norm: 0.535\n",
      "Validation - loss: -0.437, greedy reward: 0.573, sampled reward: 0.551, baseline rouge 1,2,L: {0.428, 0.183, 0.373}, model rouge 1,2,L {0.442, 0.188, 0.385}\n",
      "Weights saved in file: /home/ai2-leia/Documents/code/paul/deep_NLP/Summarization/PubMed/weights/Seq2Seq_Basic_Attn_RL_weights_epoch_0\n",
      "\n",
      "DOCUMENT:\n",
      "This study makes use of this distinction to analyze the exhaust gas concentration and fuel of the circulating fluidized bed (CFB) boiler that mainly uses wood biomass, and to develop the emission factors of Methane (CH(4)), Nitrous oxide (N(2)O). The fuels used as energy sources in the subject working sites are Wood Chip Fuel (WCF), RDF and Refused Plastic Fuel (RPF) of which heating values are 11.9 TJ/Gg, 17.1 TJ/Gg, and 31.2 TJ/Gg, respectively. The average concentrations of CH(4) and N(2)O were measured to be 2.78 ppm and 7.68 ppm, respectively. The analyzed values and data collected from the field survey were used to calculate the emission factor of CH(4) and N(2)O exhausted from the CFB boiler. As a result, the emission factors of CH(4) and N(2)O are 1.4 kg/TJ (0.9-1.9 kg/TJ) and 4.0 kg/TJ (2.9-5.3 kg/TJ) within a 95% confidence interval. Biomass combined with the combustion technology for the CFB boiler proved to be more effective in reducing the N(2)O emission, compared to the emission factor of the CFB boiler using fossil fuel.\n",
      "BASELINE:\n",
      "gas exchange and emission of UNK UNK UNK UNK UNK UNK . EOS\n",
      "GREEDY:\n",
      "determination of the gas and emissions of UNK in the fluidized bed of UNK . EOS\n",
      "SAMPLED:\n",
      "measurements and determination of the UNK and production of fuel in fluidized bed UNK UNK . EOS\n",
      "GROUND TRUTH:\n",
      "Development of methane and nitrous oxide emission factors for the biomass fired circulating fluidized bed combustion power plant.\n",
      "[0,  1100] loss: -0.532, greedy reward: 0.584, sampled reward: 0.557, rouge-1: 0.454, rouge-2: 0.209, rouge-L: 0.400, grad_norm: 0.438\n",
      "[0,  1200] loss: -0.226, greedy reward: 0.585, sampled reward: 0.573, rouge-1: 0.452, rouge-2: 0.196, rouge-L: 0.404, grad_norm: 0.381\n",
      "[0,  1300] loss: -0.307, greedy reward: 0.572, sampled reward: 0.555, rouge-1: 0.436, rouge-2: 0.184, rouge-L: 0.385, grad_norm: 0.477\n",
      "[0,  1400] loss: -0.307, greedy reward: 0.575, sampled reward: 0.561, rouge-1: 0.455, rouge-2: 0.181, rouge-L: 0.390, grad_norm: 0.509\n",
      "[0,  1500] loss: -0.234, greedy reward: 0.576, sampled reward: 0.561, rouge-1: 0.446, rouge-2: 0.205, rouge-L: 0.389, grad_norm: 0.445\n",
      "[0,  1600] loss: -0.365, greedy reward: 0.580, sampled reward: 0.560, rouge-1: 0.447, rouge-2: 0.187, rouge-L: 0.386, grad_norm: 0.482\n",
      "[0,  1700] loss: -0.062, greedy reward: 0.569, sampled reward: 0.564, rouge-1: 0.441, rouge-2: 0.190, rouge-L: 0.377, grad_norm: 0.448\n",
      "[0,  1800] loss: -0.249, greedy reward: 0.576, sampled reward: 0.566, rouge-1: 0.439, rouge-2: 0.186, rouge-L: 0.387, grad_norm: 0.364\n",
      "[0,  1900] loss: -0.307, greedy reward: 0.582, sampled reward: 0.564, rouge-1: 0.452, rouge-2: 0.197, rouge-L: 0.397, grad_norm: 1.000\n",
      "[0,  2000] loss: -0.306, greedy reward: 0.578, sampled reward: 0.562, rouge-1: 0.466, rouge-2: 0.206, rouge-L: 0.398, grad_norm: 0.435\n",
      "Validation - loss: -0.247, greedy reward: 0.576, sampled reward: 0.561, baseline rouge 1,2,L: {0.425, 0.181, 0.371}, model rouge 1,2,L {0.448, 0.191, 0.388}\n",
      "Weights saved in file: /home/ai2-leia/Documents/code/paul/deep_NLP/Summarization/PubMed/weights/Seq2Seq_Basic_Attn_RL_weights_epoch_0\n",
      "\n",
      "DOCUMENT:\n",
      "The minimally invasive nature of endoscopically placed gastrostomy tubes makes them a viable consideration in palliative care. Complications related to the procedure appear to correlate with age and underlying comorbidities.However, in many instances, the scientific basis for establishing benefit or harm from tube placement is methodologically inadequate. Decisions must be preceded by a discussion of the value and potential risk of artificial nutrition in a particular setting, respecting the wishes and beliefs of each patient and his or her family. The decision to use PEG placement for any reason should be consistent with legal and ethical principles, reflect patient autonomy over any other consideration (including beneficence), and arise from a clear determination of the goals of care (and whether the PEG placement will truly help meet those goals). Whenever possible, further studies with better design are needed to evaluate whether the use of PEG truly affects quality of life and patient outcome in palliative care. PEG tubes for decompression are placed successfully most of the time. Symptom relief occurs usually within 7 days of the procedure. Overall, the morbidity related to the PEG procedure for decompression is only slightly higher than when the same technique is used for nutritional purposes. The appropriate timing for PEG tube placement for nutritional support and for decompression throughout the course of disease progression may be difficult to determine and yet may be a factor in its overall efficiency. Only minor modifications of the basic technique used for PEG placement for nutritional purposes are required to adapt the technique to a variety of other applications in palliative care.\n",
      "BASELINE:\n",
      "the role of endoscopic gastrostomy in the management of palliative care . EOS\n",
      "GREEDY:\n",
      "the use of endoscopic gastrostomy in palliative care . EOS\n",
      "SAMPLED:\n",
      "the role of endoscopic gastrostomy in palliative care . EOS\n",
      "GROUND TRUTH:\n",
      "The role of endoscopically placed feeding or decompression tubes.\n",
      "[0,  2100] loss: -0.096, greedy reward: 0.563, sampled reward: 0.560, rouge-1: 0.438, rouge-2: 0.168, rouge-L: 0.371, grad_norm: 0.472\n",
      "[0,  2200] loss: -0.229, greedy reward: 0.587, sampled reward: 0.576, rouge-1: 0.466, rouge-2: 0.202, rouge-L: 0.409, grad_norm: 0.512\n",
      "[0,  2300] loss: -0.292, greedy reward: 0.575, sampled reward: 0.558, rouge-1: 0.440, rouge-2: 0.182, rouge-L: 0.383, grad_norm: 0.487\n",
      "[0,  2400] loss: -0.237, greedy reward: 0.561, sampled reward: 0.545, rouge-1: 0.431, rouge-2: 0.174, rouge-L: 0.363, grad_norm: 0.366\n",
      "[0,  2500] loss: -0.194, greedy reward: 0.577, sampled reward: 0.564, rouge-1: 0.453, rouge-2: 0.191, rouge-L: 0.387, grad_norm: 0.513\n",
      "[0, 19000] loss: -0.071, greedy reward: 0.580, sampled reward: 0.569, rouge-1: 0.456, rouge-2: 0.186, rouge-L: 0.387, grad_norm: 0.409\n",
      "Validation - loss: -0.077, greedy reward: 0.587, sampled reward: 0.580, baseline rouge 1,2,L: {0.425, 0.180, 0.371}, model rouge 1,2,L {0.465, 0.200, 0.401}\n",
      "DOCUMENT:\n",
      "The effect of preoperative whole-body washing with chlorhexidine detergent on the incidence of postoperative wound infection was assessed in a placebo-controlled trial of 1989 patients. Patients bathed or showered with chlorhexidine, placebo, or conventional bar soap, on two occasions in the 24 h before operation. The overall infection rate for patients treated with chlorhexidine was 9%, against 12.8% in the bar soap and 11.7% in the placebo groups; in the 'clean' surgery group infections were 7.2% against 10.2% and 10%, respectively. The Staphylococcus aureus infection rate in the 'clean' group was 3% for chlorhexidine against 6% for bar soap.\n",
      "BASELINE:\n",
      "the effect of preoperative washing on the incidence of infection after wound infection . EOS\n",
      "GREEDY:\n",
      "effect of whole body washing on the incidence of wound infection . EOS\n",
      "SAMPLED:\n",
      "effect of whole body washing on the incidence of wound infection . EOS\n",
      "GROUND TRUTH:\n",
      "A placebo-controlled trial of the effect of two preoperative baths or showers with chlorhexidine detergent on postoperative wound infection rates.\n",
      "[0, 19100] loss: -0.090, greedy reward: 0.586, sampled reward: 0.577, rouge-1: 0.465, rouge-2: 0.197, rouge-L: 0.398, grad_norm: 0.419\n",
      "[0, 19200] loss: -0.031, greedy reward: 0.591, sampled reward: 0.590, rouge-1: 0.475, rouge-2: 0.204, rouge-L: 0.412, grad_norm: 0.417\n",
      "[0, 19300] loss: -0.091, greedy reward: 0.593, sampled reward: 0.587, rouge-1: 0.469, rouge-2: 0.208, rouge-L: 0.414, grad_norm: 0.470\n",
      "[0, 19400] loss: -0.130, greedy reward: 0.571, sampled reward: 0.560, rouge-1: 0.440, rouge-2: 0.184, rouge-L: 0.384, grad_norm: 0.445\n",
      "[0, 19500] loss: 0.019, greedy reward: 0.582, sampled reward: 0.582, rouge-1: 0.473, rouge-2: 0.199, rouge-L: 0.402, grad_norm: 0.419\n",
      "[0, 19600] loss: -0.039, greedy reward: 0.592, sampled reward: 0.589, rouge-1: 0.471, rouge-2: 0.209, rouge-L: 0.407, grad_norm: 0.384\n",
      "[0, 19700] loss: -0.118, greedy reward: 0.602, sampled reward: 0.590, rouge-1: 0.484, rouge-2: 0.217, rouge-L: 0.421, grad_norm: 0.394\n",
      "[0, 19800] loss: -0.103, greedy reward: 0.606, sampled reward: 0.596, rouge-1: 0.492, rouge-2: 0.213, rouge-L: 0.429, grad_norm: 0.399\n",
      "[0, 19900] loss: -0.073, greedy reward: 0.590, sampled reward: 0.581, rouge-1: 0.471, rouge-2: 0.205, rouge-L: 0.408, grad_norm: 0.419\n",
      "[0, 20000] loss: -0.054, greedy reward: 0.586, sampled reward: 0.580, rouge-1: 0.449, rouge-2: 0.186, rouge-L: 0.393, grad_norm: 0.382\n",
      "Validation - loss: -0.071, greedy reward: 0.588, sampled reward: 0.581, baseline rouge 1,2,L: {0.427, 0.182, 0.372}, model rouge 1,2,L {0.470, 0.201, 0.404}\n",
      "Weights saved in file: /home/ai2-leia/Documents/code/paul/deep_NLP/Summarization/PubMed/weights/Seq2Seq_Basic_Attn_RL_weights_epoch_0\n",
      "\n",
      "DOCUMENT:\n",
      "Forty-five patients with residual or recurrent nasal polyposis after ethmoidectomy were treated with either cetirizine at twice the daily recommended (20 mg) dose or placebo for three months. The number and size of polyps remained unchanged during the study period. Cetirizine was found to reduce nasal sneezing and rhinorrhoea effectively. The drug also had a beneficial effect on nasal obstruction in the latter part of the study. The side effects of 20 mg (double the recommended daily adult dose) of cetirizine were few and comparable to placebo.\n",
      "BASELINE:\n",
      "UNK in the treatment of nasal polyposis . a prospective study . EOS\n",
      "GREEDY:\n",
      "efficacy of UNK in the treatment of recurrent nasal polyposis . EOS\n",
      "SAMPLED:\n",
      "effect of UNK in the treatment of recurrent nasal polyposis . EOS\n",
      "GROUND TRUTH:\n",
      "The effect of cetirizine on symptoms and signs of nasal polyposis.\n",
      "[0, 20100] loss: -0.126, greedy reward: 0.594, sampled reward: 0.585, rouge-1: 0.478, rouge-2: 0.193, rouge-L: 0.419, grad_norm: 0.529\n",
      "[0, 20200] loss: -0.085, greedy reward: 0.584, sampled reward: 0.574, rouge-1: 0.463, rouge-2: 0.206, rouge-L: 0.403, grad_norm: 0.370\n",
      "[0, 20300] loss: -0.083, greedy reward: 0.599, sampled reward: 0.591, rouge-1: 0.495, rouge-2: 0.217, rouge-L: 0.424, grad_norm: 0.484\n",
      "[0, 20400] loss: -0.073, greedy reward: 0.585, sampled reward: 0.576, rouge-1: 0.467, rouge-2: 0.202, rouge-L: 0.407, grad_norm: 0.556\n",
      "[0, 20500] loss: -0.109, greedy reward: 0.589, sampled reward: 0.579, rouge-1: 0.484, rouge-2: 0.210, rouge-L: 0.410, grad_norm: 0.493\n",
      "[0, 20600] loss: -0.120, greedy reward: 0.598, sampled reward: 0.585, rouge-1: 0.481, rouge-2: 0.215, rouge-L: 0.423, grad_norm: 0.453\n",
      "[0, 20700] loss: -0.037, greedy reward: 0.588, sampled reward: 0.585, rouge-1: 0.470, rouge-2: 0.213, rouge-L: 0.407, grad_norm: 0.398\n",
      "[0, 20800] loss: -0.058, greedy reward: 0.576, sampled reward: 0.574, rouge-1: 0.458, rouge-2: 0.183, rouge-L: 0.386, grad_norm: 0.490\n",
      "[0, 20900] loss: -0.102, greedy reward: 0.597, sampled reward: 0.591, rouge-1: 0.467, rouge-2: 0.225, rouge-L: 0.415, grad_norm: 0.563\n",
      "[0, 21000] loss: -0.067, greedy reward: 0.593, sampled reward: 0.586, rouge-1: 0.482, rouge-2: 0.197, rouge-L: 0.416, grad_norm: 0.480\n",
      "Validation - loss: -0.073, greedy reward: 0.587, sampled reward: 0.581, baseline rouge 1,2,L: {0.425, 0.179, 0.370}, model rouge 1,2,L {0.469, 0.201, 0.405}\n",
      "DOCUMENT:\n",
      "Gastrointestinal fistula is the most serious complication of esophageal and gastric cardiac cancer surgery. According to occurrence of organ, gastrointestinal fistula can be divided into anastomotic fistula, gastric fistula; According to occurrence site, fistula can be divided into cervical fistula, thoracic fistula; According to time of occurrence, can be divided into early, middle and late fistula. There are special types of fistula including ‘thoracic cavity’-stomach-bronchial fistula, ‘thoracic cavity’-stomach-aortic fistula. Early diagnosis needs familiarity with various types of clinical gastrointestinal fistulas. However, Prevention of gastrointestinal fistula is better than cure, including perioperative nutritional support, respiratory tract management, and acid suppression, positive treatment of complications, antibiotic prophylaxis, and gastrointestinal decompression and eating timing. Prevention can effectively reduce the incidence of postoperative gastrointestinal fistula. Collectively, early diagnosis and treatment, nutritional supports are key to reducing mortality of gastrointestinal fistula.\n",
      "BASELINE:\n",
      "gastrointestinal fistula in the surgical treatment of esophageal cancer . EOS\n",
      "GREEDY:\n",
      "the prevention of gastrointestinal fistula and esophageal fistula . EOS\n",
      "SAMPLED:\n",
      "the prevention of gastrointestinal fistula in the gastrointestinal tract . EOS\n",
      "GROUND TRUTH:\n",
      "Cure and prevention strategy for postoperative gastrointestinal fistula after esophageal and gastric cardiac cancer surgery.\n",
      "[0, 21100] loss: -0.085, greedy reward: 0.590, sampled reward: 0.582, rouge-1: 0.460, rouge-2: 0.203, rouge-L: 0.404, grad_norm: 0.518\n",
      "[0, 21200] loss: -0.042, greedy reward: 0.590, sampled reward: 0.587, rouge-1: 0.478, rouge-2: 0.203, rouge-L: 0.409, grad_norm: 0.558\n",
      "[0, 21300] loss: -0.115, greedy reward: 0.588, sampled reward: 0.578, rouge-1: 0.464, rouge-2: 0.204, rouge-L: 0.404, grad_norm: 0.467\n",
      "[0, 21400] loss: -0.064, greedy reward: 0.591, sampled reward: 0.587, rouge-1: 0.471, rouge-2: 0.207, rouge-L: 0.408, grad_norm: 0.375\n",
      "[0, 21500] loss: -0.066, greedy reward: 0.585, sampled reward: 0.578, rouge-1: 0.455, rouge-2: 0.191, rouge-L: 0.399, grad_norm: 0.385\n",
      "[0, 21600] loss: -0.055, greedy reward: 0.587, sampled reward: 0.577, rouge-1: 0.466, rouge-2: 0.195, rouge-L: 0.401, grad_norm: 0.398\n",
      "[0, 21700] loss: -0.136, greedy reward: 0.596, sampled reward: 0.586, rouge-1: 0.474, rouge-2: 0.213, rouge-L: 0.416, grad_norm: 0.494\n",
      "[0, 21800] loss: -0.001, greedy reward: 0.595, sampled reward: 0.595, rouge-1: 0.491, rouge-2: 0.215, rouge-L: 0.416, grad_norm: 0.373\n",
      "[0, 21900] loss: -0.094, greedy reward: 0.583, sampled reward: 0.570, rouge-1: 0.469, rouge-2: 0.195, rouge-L: 0.395, grad_norm: 0.399\n",
      "[0, 22000] loss: 0.005, greedy reward: 0.589, sampled reward: 0.589, rouge-1: 0.476, rouge-2: 0.197, rouge-L: 0.409, grad_norm: 0.387\n",
      "Validation - loss: -0.066, greedy reward: 0.588, sampled reward: 0.582, baseline rouge 1,2,L: {0.425, 0.181, 0.372}, model rouge 1,2,L {0.471, 0.202, 0.406}\n",
      "Weights saved in file: /home/ai2-leia/Documents/code/paul/deep_NLP/Summarization/PubMed/weights/Seq2Seq_Basic_Attn_RL_weights_epoch_0\n",
      "\n",
      "DOCUMENT:\n",
      "To improve multiple sclerosis (MS) research by introducing a new type of contrast, namely, the combination of fluid-attenuated inversion recovery (FLAIR) data acquired at 3.0 T and 7.0 T susceptibility-weighted imaging (SWI) phase data. The approach of this new contrast is whole-brain coverage with 3.0 T-FLAIR data for lesion detection--currently limited at 7.0 T due to specific absorption rate (SAR) limits--overlaid with high-resolution, small vessel, and iron-related 7.0 T SWI contrast. Lesion analysis in terms of penetrating veins and local iron depositions were performed.\n",
      "BASELINE:\n",
      "a novel approach to the recovery of multiple sclerosis . EOS\n",
      "GREEDY:\n",
      "a phase i clinical trial of fluid recovery for multiple sclerosis . EOS\n",
      "SAMPLED:\n",
      "the use of flair and recovery for multiple sclerosis and recovery . EOS\n",
      "GROUND TRUTH:\n",
      "Analysis of multiple sclerosis lesions using a fusion of 3.0 T FLAIR and 7.0 T SWI phase: FLAIR SWI.\n",
      "[0, 22100] loss: -0.077, greedy reward: 0.575, sampled reward: 0.570, rouge-1: 0.452, rouge-2: 0.193, rouge-L: 0.384, grad_norm: 0.453\n",
      "[0, 22200] loss: -0.066, greedy reward: 0.581, sampled reward: 0.578, rouge-1: 0.455, rouge-2: 0.193, rouge-L: 0.394, grad_norm: 0.462\n",
      "[0, 22300] loss: -0.045, greedy reward: 0.586, sampled reward: 0.583, rouge-1: 0.479, rouge-2: 0.214, rouge-L: 0.402, grad_norm: 0.480\n",
      "[0, 22400] loss: -0.087, greedy reward: 0.584, sampled reward: 0.577, rouge-1: 0.468, rouge-2: 0.203, rouge-L: 0.396, grad_norm: 0.516\n",
      "[0, 22500] loss: -0.083, greedy reward: 0.607, sampled reward: 0.598, rouge-1: 0.498, rouge-2: 0.231, rouge-L: 0.432, grad_norm: 0.319\n",
      "[0, 22600] loss: -0.071, greedy reward: 0.602, sampled reward: 0.594, rouge-1: 0.493, rouge-2: 0.225, rouge-L: 0.428, grad_norm: 0.437\n",
      "[0, 22700] loss: -0.125, greedy reward: 0.592, sampled reward: 0.580, rouge-1: 0.471, rouge-2: 0.211, rouge-L: 0.420, grad_norm: 0.597\n",
      "[0, 22800] loss: 0.014, greedy reward: 0.584, sampled reward: 0.586, rouge-1: 0.464, rouge-2: 0.188, rouge-L: 0.392, grad_norm: 0.374\n",
      "[0, 22900] loss: -0.099, greedy reward: 0.602, sampled reward: 0.594, rouge-1: 0.484, rouge-2: 0.226, rouge-L: 0.423, grad_norm: 0.438\n",
      "[0, 23000] loss: -0.086, greedy reward: 0.580, sampled reward: 0.573, rouge-1: 0.458, rouge-2: 0.200, rouge-L: 0.395, grad_norm: 0.407\n",
      "Validation - loss: -0.060, greedy reward: 0.588, sampled reward: 0.583, baseline rouge 1,2,L: {0.426, 0.181, 0.372}, model rouge 1,2,L {0.470, 0.203, 0.407}\n",
      "Weights saved in file: /home/ai2-leia/Documents/code/paul/deep_NLP/Summarization/PubMed/weights/Seq2Seq_Basic_Attn_RL_weights_epoch_0\n",
      "\n",
      "DOCUMENT:\n",
      "In the title compound, C(18)H(21)NO(4), the hydrogenated six-membered ring of the carbazole unit adopts a half-chair conformation. The dioxolane ring and ethyl-acetate substituent point to opposite sides of the carbazole plane. The ethyl-acetate substituent adopts an essentially fully extended conformation, and its mean plane forms a dihedral angle of 83.8 (1)° with respect to the carbazole mean plane. The mol-ecules are arranged into stacks in which the carbazole planes form a dihedral angle of 4.4 (1)° and have an approximate inter-planar separation of 3.6 Å.\n",
      "BASELINE:\n",
      "ethyl 5 6 7 8 UNK UNK UNK . EOS\n",
      "GREEDY:\n",
      "3 4 UNK 1 yl phen yl 1 2 UNK . EOS\n",
      "SAMPLED:\n",
      "3 4 fluoro phen yl 3 4 UNK . EOS\n",
      "GROUND TRUTH:\n",
      "Ethyl 2-(1,2,3,4-tetrahydro-spiro-[carba-zole-3,2'-[1,3]dioxolan]-9-yl)acetate.\n",
      "[0, 23100] loss: -0.036, greedy reward: 0.579, sampled reward: 0.577, rouge-1: 0.451, rouge-2: 0.198, rouge-L: 0.392, grad_norm: 0.409\n",
      "[0, 23200] loss: -0.059, greedy reward: 0.586, sampled reward: 0.580, rouge-1: 0.464, rouge-2: 0.210, rouge-L: 0.404, grad_norm: 0.427\n"
     ]
    }
   ],
   "source": [
    "params = {key : value for key, value in summarize_net.__dict__.items() if not key.startswith('__') and not key.startswith('_')\n",
    "          and not callable(key) and str(type(value)).find('tensorflow') == -1}\n",
    "model_name = summarize_net.__class__.__name__ + '_RL'\n",
    "\n",
    "if not DEBUG_MODE:\n",
    "    timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "    log_file = os.path.join(log_dir, '{}_train_log_{}.txt'.format(model_name, timestamp))\n",
    "    log_description = '0.1 unk/0.7 rouge-l-f/0.2 coherence reward, 0.0005 lr, 32 batch size, params: {}\\n'.format(params)\n",
    "    log = open(log_file, 'w')\n",
    "    log.close()\n",
    "    functions.write_to_log(log_description, log_file)\n",
    "\n",
    "baseline_sess = tf.InteractiveSession(graph=baseline_graph, config=tf.ConfigProto(allow_soft_placement=True))\n",
    "summarize_sess = tf.InteractiveSession(graph=summarize_graph, config=tf.ConfigProto(allow_soft_placement=True)) \n",
    "coherence_sess = tf.InteractiveSession(graph=coherence_graph, config=tf.ConfigProto(allow_soft_placement=True))\n",
    "\n",
    "summarize_sess.run(summarize_init)\n",
    "if not DEBUG_MODE:\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "    \n",
    "baseline_sess.run(baseline_init)\n",
    "coherence_sess.run(coherence_init)\n",
    "\n",
    "baseline_saver = tf.train.Saver(var_list=baseline_vars)\n",
    "baseline_saver.restore(baseline_sess, summarize_ckpt_file)\n",
    "\n",
    "summarize_saver = tf.train.Saver(var_list=summarize_vars)\n",
    "summarize_saver.restore(summarize_sess, summarize_ckpt_file)\n",
    "\n",
    "coherence_saver = tf.train.Saver(var_list=coherence_vars)\n",
    "coherence_saver.restore(coherence_sess, coherence_ckpt_file)\n",
    "\n",
    "best_val_reward = 0.0\n",
    "epoch = 0\n",
    "for itr in range(1, n_iters+1):\n",
    "    examples, ep = train_batcher.next_batch()\n",
    "    if ep == 1:\n",
    "        try:\n",
    "            train_data = next(train_partition_loader)\n",
    "        except:\n",
    "            epoch += 1\n",
    "            train_partition_loader = data_partition_loader(train_files)\n",
    "            train_data = next(train_partition_loader)\n",
    "        train_batcher = data_batcher.Data_Batcher(train_data, batch_size)\n",
    "        examples, ep = train_batcher.next_batch()\n",
    "    \n",
    "    inputs = [example.source_ids for example in examples]\n",
    "    input_lens = [example.source_len for example in examples]\n",
    "    dummy_dec_inputs = np.zeros_like([example.target_ids for example in examples], dtype=int)\n",
    "    #contexts = [example.source_text for example in examples]\n",
    "    target_ids = [example.target_ids for example in examples]\n",
    "\n",
    "    # baseline model\n",
    "    feed_dict = {baseline_net.enc_inputs : inputs,\n",
    "                 baseline_net.dec_inputs : dummy_dec_inputs,\n",
    "                 baseline_net.enc_lens : input_lens,\n",
    "                 baseline_net.dropout_keep_prob : 1.0,\n",
    "                 baseline_net.teacher_forcing : False,\n",
    "                 baseline_net.teacher_forcing_mask : [1 for _ in range(s_pad_len)],\n",
    "                 baseline_net.is_training : False,\n",
    "                 baseline_net.sample_decoding : False}\n",
    "\n",
    "    baseline_ids = baseline_sess.run(baseline_predictions, feed_dict=feed_dict)\n",
    "    \n",
    "    # greedy decoding\n",
    "    feed_dict = {summarize_net.enc_inputs : inputs,\n",
    "                 summarize_net.dec_inputs : dummy_dec_inputs,\n",
    "                 summarize_net.enc_lens : input_lens,\n",
    "                 summarize_net.dropout_keep_prob : 1.0,\n",
    "                 summarize_net.teacher_forcing : False,\n",
    "                 summarize_net.teacher_forcing_mask : [1 for _ in range(s_pad_len)],\n",
    "                 summarize_net.is_training : False,\n",
    "                 summarize_net.sample_decoding : False,\n",
    "                 targets : target_ids}\n",
    "\n",
    "    greedy_ids = summarize_sess.run(summarize_predictions, feed_dict=feed_dict)\n",
    "    greedy_reward = calculate_reward(greedy_ids, target_ids)\n",
    "    \n",
    "    # run REINFORCE optimization\n",
    "    feed_dict = {summarize_net.enc_inputs : inputs,\n",
    "                 summarize_net.dec_inputs : dummy_dec_inputs,\n",
    "                 summarize_net.enc_lens : input_lens,\n",
    "                 summarize_net.dropout_keep_prob : 1.0,\n",
    "                 summarize_net.teacher_forcing : False,\n",
    "                 summarize_net.teacher_forcing_mask : [1 for _ in range(s_pad_len)],\n",
    "                 summarize_net.is_training : False,\n",
    "                 summarize_net.sample_decoding : True,\n",
    "                 targets : target_ids,\n",
    "                 baseline_reward : greedy_reward}\n",
    "    rl_loss, sampled_reward, grad_norm, _ = summarize_sess.run([loss, reward, gradient_norm, optimizer], feed_dict=feed_dict)\n",
    "    \n",
    "    scores = [(score['rouge-1']['r'], score['rouge-2']['r'], score['rouge-l']['r']) for score \n",
    "          in rouge.get_scores(ids_to_text(greedy_ids, vocab_lookup), ids_to_text(target_ids, vocab_lookup))]\n",
    "    rouge_1, rouge_2, rouge_L = tuple(np.mean(np.array(scores), axis=0))\n",
    "    \n",
    "    if itr % display_interval == 0 or itr == 1:     \n",
    "        log_string = ('[%d, %5d] loss: %.3f, greedy reward: %.3f, sampled reward: %.3f, rouge-1: %.3f, rouge-2: %.3f, \\\n",
    "rouge-L: %.3f, grad_norm: %.3f' % (epoch, itr, rl_loss, np.mean(greedy_reward), np.mean(sampled_reward), \n",
    "                                   rouge_1, rouge_2, rouge_L, grad_norm))\n",
    "\n",
    "        if not DEBUG_MODE:\n",
    "            functions.write_to_log(log_string, log_file)\n",
    "        print(log_string)\n",
    "    \n",
    "    if itr % val_interval == 0:\n",
    "        val_loss, val_greedy_reward, val_sampled_reward = 0.0, 0.0, 0.0\n",
    "        baseline_rouge_scores, model_rouge_scores = [], []\n",
    "        for i in range(int(len(val_batcher.data)/val_batcher.batch_size)):\n",
    "            examples, ep = val_batcher.next_batch()\n",
    "            if ep == 1:\n",
    "                try:\n",
    "                    val_data = next(val_partition_loader)\n",
    "                except:\n",
    "                    val_partition_loader = data_partition_loader(val_files)\n",
    "                    val_data = next(val_partition_loader)\n",
    "                val_batcher = data_batcher.Data_Batcher(val_data, batch_size)\n",
    "                examples, ep = val_batcher.next_batch()\n",
    "\n",
    "            inputs = [example.source_ids for example in examples]\n",
    "            input_lens = [example.source_len for example in examples]\n",
    "            dummy_dec_inputs = np.zeros_like([example.target_ids for example in examples], dtype=int)\n",
    "            #contexts = [example.source_text for example in examples]\n",
    "            target_ids = [example.target_ids for example in examples]\n",
    "\n",
    "            # baseline model\n",
    "            feed_dict = {baseline_net.enc_inputs : inputs,\n",
    "                         baseline_net.dec_inputs : dummy_dec_inputs,\n",
    "                         baseline_net.enc_lens : input_lens,\n",
    "                         baseline_net.dropout_keep_prob : 1.0,\n",
    "                         baseline_net.teacher_forcing : False,\n",
    "                         baseline_net.teacher_forcing_mask : [1 for _ in range(s_pad_len)],\n",
    "                         baseline_net.is_training : False,\n",
    "                         baseline_net.sample_decoding : False}\n",
    "\n",
    "            baseline_ids = baseline_sess.run(baseline_predictions, feed_dict=feed_dict)\n",
    "\n",
    "            # greedy decoding\n",
    "            feed_dict = {summarize_net.enc_inputs : inputs,\n",
    "                         summarize_net.dec_inputs : dummy_dec_inputs,\n",
    "                         summarize_net.enc_lens : input_lens,\n",
    "                         summarize_net.dropout_keep_prob : 1.0,\n",
    "                         summarize_net.teacher_forcing : False,\n",
    "                         summarize_net.teacher_forcing_mask : [1 for _ in range(s_pad_len)],\n",
    "                         summarize_net.is_training : False,\n",
    "                         summarize_net.sample_decoding : False,\n",
    "                         targets : target_ids}\n",
    "\n",
    "            greedy_ids = summarize_sess.run(summarize_predictions, feed_dict=feed_dict)\n",
    "            greedy_reward = calculate_reward(greedy_ids, target_ids)\n",
    "\n",
    "            # run REINFORCE optimization\n",
    "            feed_dict = {summarize_net.enc_inputs : inputs,\n",
    "                         summarize_net.dec_inputs : dummy_dec_inputs,\n",
    "                         summarize_net.enc_lens : input_lens,\n",
    "                         summarize_net.dropout_keep_prob : 1.0,\n",
    "                         summarize_net.teacher_forcing : False,\n",
    "                         summarize_net.teacher_forcing_mask : [1 for _ in range(s_pad_len)],\n",
    "                         summarize_net.is_training : False,\n",
    "                         summarize_net.sample_decoding : True,\n",
    "                         targets : target_ids,\n",
    "                         baseline_reward : greedy_reward}\n",
    "            rl_loss, sampled_reward = summarize_sess.run([loss, reward], feed_dict=feed_dict)\n",
    "            val_loss += ((rl_loss - val_loss)/(i+1))\n",
    "            val_greedy_reward += ((np.mean(greedy_reward) - val_greedy_reward)/(i+1))\n",
    "            val_sampled_reward += ((np.mean(sampled_reward)- val_sampled_reward)/(i+1))\n",
    "            #val_loss.append(rl_loss)\n",
    "            #val_greedy_reward.append(np.mean(greedy_reward))\n",
    "            #val_sampled_reward.append(np.mean(sampled_reward))\n",
    "            \n",
    "            baseline_scores = [(score['rouge-1']['r'], score['rouge-2']['r'], score['rouge-l']['r']) for score \n",
    "              in rouge.get_scores(ids_to_text(baseline_ids, vocab_lookup), ids_to_text(target_ids, vocab_lookup))]\n",
    "            baseline_rouge_scores.append(np.mean(np.array(baseline_scores), axis=0))\n",
    "            model_scores = [(score['rouge-1']['r'], score['rouge-2']['r'], score['rouge-l']['r']) for score \n",
    "              in rouge.get_scores(ids_to_text(greedy_ids, vocab_lookup), ids_to_text(target_ids, vocab_lookup))]\n",
    "            model_rouge_scores.append(np.mean(np.array(model_scores), axis=0))\n",
    "            \n",
    "            if (i+1)*val_batcher.batch_size >= 10000:\n",
    "                break\n",
    "        #val_loss = np.mean(val_loss)\n",
    "        #val_greedy_reward = np.mean(val_greedy_reward)\n",
    "        #val_sampled_reward = np.mean(val_sampled_reward)\n",
    "        baseline_rouge_scores = np.mean(baseline_rouge_scores, axis=0)\n",
    "        model_rouge_scores = np.mean(model_rouge_scores, axis=0)\n",
    "        log_string = ('Validation - loss: %.3f, greedy reward: %.3f, sampled reward: %.3f, baseline rouge 1,2,L: \\\n",
    "{%.3f, %.3f, %.3f}, model rouge 1,2,L {%.3f, %.3f, %.3f}' % (val_loss, val_greedy_reward, val_sampled_reward, \n",
    "                                                             baseline_rouge_scores[0], baseline_rouge_scores[1], \n",
    "                                                             baseline_rouge_scores[2], model_rouge_scores[0],\n",
    "                                                             model_rouge_scores[1], model_rouge_scores[2]))\n",
    "\n",
    "        if not DEBUG_MODE:\n",
    "            functions.write_to_log(log_string, log_file)\n",
    "        print(log_string)\n",
    "            \n",
    "        if not DEBUG_MODE:\n",
    "            if val_greedy_reward > best_val_reward:\n",
    "                best_val_reward = val_greedy_reward\n",
    "                weights_prefix = '{}_weights_epoch_{}'.format(model_name, epoch)\n",
    "                log_msg = \"Weights saved in file: {}\\n\".format(os.path.join(weights_dir, weights_prefix))\n",
    "                print(log_msg)\n",
    "                #saver.save(summarize_sess, os.path.join(weights_dir, weights_prefix))\n",
    "                functions.write_to_log(log_msg, log_file) \n",
    "                \n",
    "    if itr % deploy_interval == 0:\n",
    "        examples, ep = deploy_batcher.next_batch()\n",
    "    \n",
    "        inputs = [example.source_ids for example in examples]\n",
    "        input_lens = [example.source_len for example in examples]\n",
    "        dummy_dec_inputs = np.zeros_like([example.target_ids for example in examples], dtype=int)\n",
    "        #contexts = [example.source_text for example in examples]\n",
    "        target_ids = [example.target_ids for example in examples]\n",
    "\n",
    "        # baseline model\n",
    "        feed_dict = {baseline_net.enc_inputs : inputs,\n",
    "                     baseline_net.dec_inputs : dummy_dec_inputs,\n",
    "                     baseline_net.enc_lens : input_lens,\n",
    "                     baseline_net.dropout_keep_prob : 1.0,\n",
    "                     baseline_net.teacher_forcing : False,\n",
    "                     baseline_net.teacher_forcing_mask : [1 for _ in range(s_pad_len)],\n",
    "                     baseline_net.is_training : False,\n",
    "                     baseline_net.sample_decoding : False}\n",
    "\n",
    "        baseline_ids = baseline_sess.run(baseline_predictions, feed_dict=feed_dict)\n",
    "    \n",
    "        # greedy decoding\n",
    "        feed_dict = {summarize_net.enc_inputs : inputs,\n",
    "                     summarize_net.dec_inputs : dummy_dec_inputs,\n",
    "                     summarize_net.enc_lens : input_lens,\n",
    "                     summarize_net.dropout_keep_prob : 1.0,\n",
    "                     summarize_net.teacher_forcing : False,\n",
    "                     summarize_net.teacher_forcing_mask : [1 for _ in range(s_pad_len)],\n",
    "                     summarize_net.is_training : False,\n",
    "                     summarize_net.sample_decoding : False,\n",
    "                     targets : target_ids}\n",
    "\n",
    "        greedy_ids = summarize_sess.run(summarize_predictions, feed_dict=feed_dict)\n",
    "        greedy_reward = calculate_reward(greedy_ids, target_ids)\n",
    "\n",
    "        # run REINFORCE optimization\n",
    "        feed_dict = {summarize_net.enc_inputs : inputs,\n",
    "                     summarize_net.dec_inputs : dummy_dec_inputs,\n",
    "                     summarize_net.enc_lens : input_lens,\n",
    "                     summarize_net.dropout_keep_prob : 1.0,\n",
    "                     summarize_net.teacher_forcing : False,\n",
    "                     summarize_net.teacher_forcing_mask : [1 for _ in range(s_pad_len)],\n",
    "                     summarize_net.is_training : False,\n",
    "                     summarize_net.sample_decoding : True,\n",
    "                     targets : target_ids,\n",
    "                     baseline_reward : greedy_reward}\n",
    "        sampled_ids = summarize_sess.run(summarize_predictions, feed_dict=feed_dict)    \n",
    "\n",
    "        baseline_summaries = ids_to_text(baseline_ids, vocab_lookup)\n",
    "        sampled_summaries = ids_to_text(sampled_ids, vocab_lookup)\n",
    "        greedy_summaries = ids_to_text(greedy_ids, vocab_lookup)\n",
    "        log_string = ('DOCUMENT:\\n{}\\nBASELINE:\\n{}\\nGREEDY:\\n{}\\nSAMPLED:\\n{}\\nGROUND TRUTH:\\n{}'\n",
    "                      .format(examples[0].source_text, baseline_summaries[0], greedy_summaries[0],\n",
    "                              sampled_summaries[0], examples[0].target_text))\n",
    "        print(log_string)\n",
    "        if not DEBUG_MODE:\n",
    "            functions.write_to_log(log_string, log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
